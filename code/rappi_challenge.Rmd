---
title: "rappi_challenge"
author: "Emiliano Ramírez"
date: "2022-07-14"
output:
  pdf_document:
    latex_engine: xelatex
  html_document:
    df_print: paged
editor_options:
  chunk_output_type: inline
---

```{r setup, include=FALSE}

library(tidyverse)
library(ggplot2)
library(dplyr)
library(readxl)
library(skimr)
library(scales)
library(lubridate)
library(jsonlite)
library(pastecs)
library(corrplot)
library(NbClust)
library(factoextra) 
library(caret)

knitr::opts_chunk$set(echo = FALSE)
knitr::opts_knit$set(root.dir = "D:/Emiliano/Rappi")

setwd("D:/Emiliano/Rappi")

options(scipen=9)
```

Leemos base de datos y proporcionamos formato adecuado ya que tenemos columnas JSON y otros contratiempos con la base. También, procesamos variables 

```{r, warning=FALSE, echo=TRUE}
df <- read.csv("raw/ds_challenge_data.csv")


#vemos que existe una columna en formato json por lo que la formatearemos

#creamos función para deparse de collumna en formato json
ParseJSONColumn <- function(x)  {
  str_c("[ ", str_c(x, collapse = ",", sep=" "), " ]")  %>%
    fromJSON(flatten = T) %>%
    as_tibble()
}

#seleccionamos columna que tiene formato json
dispositivo <- df %>% select(dispositivo)

dispositivo_unj <- dispositivo  %>%
  map_dfc(.f = ParseJSONColumn)


#eliminamos la variable model porque es constante en toda la base
df <- bind_cols(df, dispositivo_unj) %>% select(-c(dispositivo, model)) 

#notemos que tenemos varias variables que deben ser declaradas como categóricas
#para su correcto tratamiento.

#Estas variables son: genero, estableciemiento, ciudad, tipo tarjeta (tipo_tc),
#status_txn, is_prime, fraude, device_Score y os.

#damos un poco de limipieza a algunas variables antes de su procesamiento
df <- df %>% mutate(genero=ifelse(genero=="--", NA, genero),
                    establecimiento=ifelse(establecimiento=="N/A",NA,
                                           ifelse(establecimiento=="",NA,establecimiento)),
                    ciudad=ifelse(ciudad=="", NA, ifelse(ciudad=="N/A",NA,ciudad)),
                    os=ifelse(os==".", NA, os))

# en genero: 1 mujer 0 hombre
# factores: establecimiento, ciudad, 
# 1 tarjeta fisica  0 virtual
df <- df %>% mutate(d_genero=ifelse(genero=='F',1,ifelse(genero=='M',0,NA)),
                    establecimiento=as.factor(establecimiento),
                    ciudad=as.factor(ciudad),
                    d_tarj=ifelse(tipo_tc=="Física", 1, 0),
                    status_txn=as.factor(status_txn),
                    d_is_prime=ifelse(is_prime=="True", 1, 0),
                    d_fraude=ifelse(fraude=="True",1,0),
                    os=as.factor(os),
                    fecha=as.Date(dmy(fecha)))
```


Obtenemos un panorama general de la base de datos y sus variables, así como estadísticos descriptivos que nos pueden ayudar a tener un conocimiento inicial de los datos. 


```{r, warning=FALSE, echo=TRUE}
df %>% skim()
```

```{r, warning=FALSE, echo=TRUE}
summary(df$d_genero)

```

El 44.2 % de la muestra es del sexo femenino y existen 2730 missings.

```{r, warning=FALSE, echo=TRUE}
stat.desc(df$linea_tc)

```

La mediana es casi igual a la media de la distribución de la var de linea de crédito por lo que es factible suponer que la distribución es simétrica, la proporción de la desviación estándar con respecto a la media es del 35%, por lo que las colas no se separan mucho del centro y, por ende, es una muestra homogénea.


```{r, warning=FALSE, echo=TRUE}
stat.desc(df$monto)

hist(x=df$monto)


```

El monto de las transacciones no supera los 1,000 pesos. Además, su distribución exhibe un comportamiento uniforme y simétrico ya que la media es casi igual que la mediana y su plot lo muestra.

```{r, warning=FALSE, echo=TRUE}
#creamos función para sacar la moda
Mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

df_mode <- df %>% summarise_each(funs = Mode, ID_USER)
```

El usuario con más transacciones es el 1958.

```{r, warning=FALSE, echo=TRUE}
df_1958 <- df %>% filter(ID_USER==1958) %>% nrow
```

62 transacciones hizo el usuario 1958, en el periodo de un mes.

Suponemos que el sistema operativo "%%" es diferente a Android pero no es web (como ios o harmonyOS).

```{r, warning=FALSE, echo=TRUE}
summary(df$os)
```

La frecuencia de los distintos sistemas operativos está balanceada.

```{r, warning=FALSE, echo=TRUE}
summary(df$d_tarj)
```

El 70 por ciento de las compras hechas en esta base son con tarjeta física.


```{r, warning=FALSE, echo=TRUE}
summary(df$d_status_txn)
```

Cerca del 70 por ciento de las compras son aceptadas.

```{r, warning=FALSE, echo=TRUE}
summary(df$d_is_prime)

```

Solo el 13 por ciento de la muestra tiene suscripción prime.


```{r, warning=FALSE, echo=TRUE}
summary(df$d_fraude)

```

El 3 por ciento de la muestra está clasificada como compra fraudulenta.



```{r, warning=FALSE, echo=TRUE}
summary(df$d_fraude==1 & df$d_status_txn==1)
```

El 2 por ciento de las transacciones donde la clasificación era fraudulenta la compra fue aceptada.


```{r, warning=FALSE, echo=TRUE}
xtabs(~  genero + fraude, data = df)

xtabs(~  genero + status_txn, data = df)


xtabs(~  fraude + os, data = df)


xtabs(~  is_prime + os, data = df)

hist(x=df$ID_USER)
```

- El sexo masculino tiene 16\% más observaciones registradas como fraudulentas.
- El sexo masculino tiene 26\% más transacciones aceptadas que el sexo femenino.
- El parecer la frecuencia de las transacciones categorizadas como fraudulentas están balanceadas.
- No parece haber mayor preferencia por la suscripción a través de los distintos os.
- La distribución de la frecuencia de aparición de los usuarios muestra un comportamiento uniforme.

¿Existe alguna concentración de monto de la transacción de algún usuario?


```{r, warning=FALSE, echo=TRUE}
ggplot(df, aes(x=ID_USER, y=monto)) +
  geom_point() +
  theme(legend.position="none")
```


Ahora creemos una matriz de correlación lineal para ver si exsite estructura de dependencia linealentre las variables numéricas.


```{r, warning=FALSE, echo=TRUE}
df_correlations <- df %>% select(c(monto, linea_tc, interes_tc, dcto, 
                                   cashback))

matrix_df <- as.matrix(df_correlations)
mat_corr <- cor(matrix_df)
corrplot(mat_corr, method="color")
```

Observando la matriz de correlaciones no existe correlación lineal evidente entre las variables numéricas. 

Para observar el 'efecto' de las variables categóricas en las variables numéricas haremos los siguientes boxplots.

```{r, warning=FALSE, echo=TRUE}
boxplot(df$monto ~ df$fraude, main='Monto por categoría de fraude',xlab='Fraude',ylab='Monto')

boxplot(df$monto ~ df$os, main='Monto por sistema op.',xlab='os',ylab='Monto')

boxplot(df$monto ~ df$is_prime, main='Monto por suscrp. prime.',xlab='prime',ylab='Monto')

boxplot(df$monto ~ df$genero, main='Monto por género.',xlab='genero',ylab='Monto')

boxplot(df$monto ~ df$ciudad, main='Monto por ciudad',xlab='ciudad',ylab='Monto')

boxplot(df$monto ~ df$establecimiento, main='Monto por establecimiento',xlab='establecimiento',ylab='Monto')

boxplot(df$monto ~ df$hora, main='Monto por hora',xlab='Hora',ylab='Monto')

boxplot(df$linea_tc ~ df$genero, main='linea de crédito por genero',xlab='genero',ylab='Monto')

boxplot(df$linea_tc ~ df$fraude, main='Línea de crédito por categoría de fraude',xlab='Fraude',ylab='Línea de crédto')

boxplot(df$interes_tc ~ df$fraude, main='Tasa de interés por categoría de fraude',xlab='Fraude',ylab='Tasa de interés')
```

Al parecer todos los grupos que se generan están balanceados en la muestra.

En conclusión, no se encontraron patrones o indicios de algún mecanismo extraño que esté sucediendo en la base.

Procedemos a hacer la clasificación de los usuarios. El algoritmo que se usará es un algoritmo de conglomerados no jerárquico de k-medias (para variables) numéricas.


```{r, warning=FALSE, echo=TRUE}
df_num <- df %>% select(ID_USER, monto, hora, linea_tc, interes_tc, dcto, cashback, device_score)


# agreagamos los datos a nivel usuario en la base de vars num
df_prom <- df_num %>%
  group_by(ID_USER) %>%
  summarise_all(mean) %>%
  as.data.frame() %>% select(-ID_USER)

row.names(df_prom) <- df_prom$ID_USER


#ahora estandaricemos las variables ya que tienen distintas escalas entre sí 
df_prom <- scale(df_prom) 


```

Hacemos pruebas para determinar cuántos clusters hacer.

```{r, warning=FALSE, echo=TRUE}
#gráfica de codo
maxk <- 10 #número de clusters a considerar máximo
ESS <- sapply(1:maxk,function(k)kmeans(df_prom,k,nstart=10)$tot.withinss)
plot(1:maxk,ESS, type="b",pch=16)
```

La gráfica de codo nos arroja un dibujo donde podemos considerar 2 clusters. 

Ahora, veamos que nos arroja la función NbClust. Esta función considera muchas pruebas como la prueba de la silueta, KL, Hartigan, Scott, etc y escoge el veredicto que tenga más frecuencia en toda la bateria de pruebas que se hace.


```{r, warning=FALSE, echo=TRUE}
#enlace completo quiere decir que se tomará el máximo de las distancias entre dos pares
#de ítems que pertnecen cada uno a clusters diferentes.

#NbClust(data=df_prom, method = "complete")


```

En este caso arrojó que 2 clusters es lo correcto. 

Apreciemos graficamente los clusters. Nota: el porcentaje de los ejes es el porcentaje de explicación de la variación de los datos.


```{r, warning=FALSE, echo=TRUE}
set.seed(14072022) # fija la semilla por reproducibilidad
km1 <- kmeans(df_prom,centers = 2, nstart = 100)
#el porcentaje de los ejes es el porcentaje de explicación de la variación de los datos 
#fviz_cluster(km1, 
#             data = df_prom, 
#             ellipse.type = "euclid", 
#             star.plot = T, 
#             repel = T,
#             ggtheme = theme(legend.position = "bottom"))

```


Ahora recuperamos la variable de categorización de cluster para pegarla a la base grande.


```{r, warning=FALSE, echo=TRUE}
clusters <- km1$cluster %>% as.data.frame() 
colnames(clusters) <- c('tipo_cliente')
df_prom <- cbind(df_prom, clusters)

df_prom <- as.data.frame(df_prom)
df_prom <- add_rownames(df_prom, var = "ID_USER")
df <- df %>% mutate(ID_USER=as.character(ID_USER))
df_prom <- df_prom %>% dplyr::select(ID_USER, tipo_cliente)

df <- df %>% left_join(df_prom, by="ID_USER")

```

Para clasificar a los usuarios usaremos un model logístico sencillo. Usaremos como variable dependiente la dummy de fraude.


```{r, warning=FALSE, echo=TRUE}
df_log <- df %>% dplyr::select(monto, hora, establecimiento, ciudad, linea_tc,
                        interes_tc, status_txn, dcto, cashback, device_score,
                        os, d_tarj, d_genero, d_is_prime, d_fraude, tipo_cliente)

```

Imputamos datos missing con un randomforest para no perder observaciones en la regresión. Nota: debido a que tarda mucho se omitió esta linea de código.


```{r, warning=FALSE, echo=TRUE}
#library(missForest)
#df_imp <- missForest(df_log)
#df_log <- df_imp$ximp

```


Para no perder observaciones se hará una imputación arbitraria de la variable género y os. Las variabes establecimiento y ciudad no se tomarán en cuenta para el modelo logístico porque casi la mitad de la muestra tiene missing en esas variables.

```{r, warning=FALSE, echo=TRUE}
df_log %>% skim()
df_log$d_genero[is.na(df_log$d_genero)] <- 1#mujer

df_log$os[is.na(df_log$os)] <- "ANDROID" 

df_log <- df_log %>% dplyr::select(-c(establecimiento, ciudad))
```

Ajustamos modelo logit con toda la especificación para ver significancia de coeficientes y poder escoger un modelo más chico.

```{r, warning=FALSE, results='hide', echo=TRUE}
modelo_logit <- glm(d_fraude ~ .:. ,family = binomial(link=logit), data = df_log)
summary(modelo_logit)
```

Dividimos base en entrenamiento y prueba.

```{r, warning=FALSE, echo=TRUE}
set.seed(14072022)
sample <- sample(c(TRUE, FALSE), nrow(df_log), replace=TRUE, prob=c(0.7,0.3))
train <- df_log[sample, ]
test <- df_log[!sample, ]
```

Nos quedamos con las explicativas que son significativas del modelo y ajustamos modelo
a muestra de entrenamiento.

```{r, warning=FALSE, echo=TRUE}
modelo_logit_red <- glm(d_fraude ~ monto + d_genero + dcto + d_is_prime + d_tarj +
                          device_score + d_is_prime + status_txn + os + cashback + tipo_cliente +
                          monto:device_score + monto:d_tarj + interes_tc:tipo_cliente + 
                          device_score:tipo_cliente + status_txn:d_genero + dcto:d_tarj +
                          cashback:device_score + cashback:d_tarj + device_score:tipo_cliente +
                          os:d_is_prime + d_genero:d_is_prime,
                        family = binomial(link=logit), data = train)

summary(modelo_logit_red)

# Devuelve los valores ajustados, del predictor lineal:
head(predict(modelo_logit_red))
# Devuelve las probabilidades ajustadas:
head(predict(modelo_logit_red,type = "response"))
```

Hacemos unos pasos intermedios para crear matriz de confusión.

```{r, warning=FALSE, echo=TRUE}

predicted <- predict(modelo_logit_red, test, type="response")
```

Encontremos cota óptima de probabilidad para maximizar precisión


```{r, warning=FALSE, echo=TRUE}
library(InformationValue)
optimal <- optimalCutoff(test$d_fraude, predicted)[1]
```

Creamos matrix de confusión.

```{r, warning=FALSE, echo=TRUE}
confusionMatrix(test$d_fraude, predicted)

```

No hay clasificación de fraude en la muestra de entrenamiento.

Evaluemos nuestra matriz de confusión. Obtendremos las siguientes métricas de nuestra tabla de confusión: sensitivity, specificity y total missclasification rate.


```{r, warning=FALSE, echo=TRUE}
sensitivity(test$d_fraude, predicted)

specificity(test$d_fraude, predicted)

misClassError(test$d_fraude, predicted, threshold=optimal)
```

Tiene un error de misclassification muy bajo por lo que el modelo no es tan malo para predecir. 

# Conclusiones

La ventaja del modelo de regresión logística es que es sencillo de utilizar y la interpretación de sus coeficientes es simple ya que solamente representan el cambio en la probabilidad de pertenecer al grupo X o no.

Podemos obtener los momios de éxito estimados:

$$ \frac{\hat{\mu}({\bf x})}{1-\hat{\mu}({\bf x})} = \exp(b_0)\exp(b_1x_1)\cdots\exp(b_px_p) $$

Los exponentes de los coeficientes estimados se llaman _factores de riesgo_.

La desventaja del modelo de clasificación logística es que supone que el costo de clasificación errónea es unitario y las probabilidades iniciales son iguales, lo cual son grandes supuestos y no responden adecuadamente a las necesidades del contexto o de información a priori que se tenga.

Existen mejores modelos como los CART (Classification and Regression Trees) ya que son más flexibles que el modelo logístico por ser modelos no paramétricos de clasificación. También, se pueden usar redes neuronales para clasificar poblaciones sin embargo no domino ese método de clasificación.

Una desventaja del modelo escogido es que puede que esté sobreajustado ya que las pruebas de sensibilidad y especificidad salieron muy cerradas implicando que tal vez no sea bueno prediciendo en nuevas muestras de prueba

El modelo usa como variable significativa la categorización que hice con el algorítmo de k-medias, por lo que da una pauta para creer que sí existen tipos de clientes procilives al uso fraudulento del crédito y que con pocos demográficos y variables explicativas se puede categorizar. 

El modelo no es bueno clasificando positivamente los casos fraudulentos pues no hizo ninguna clasificación positiva, no obstante, su error de claisifcación para los casos negativos es muy bajo (del 3%). Por lo que al menos no se equivoca en determinar una transacción no fraudulenta. 

Los datos parecen estar balanceados en todos los sentidos ya que no había patrones evidentes de correlación o de estructuras de dependencia entre variables o conjuntos de ellas. Para saber si existiera alguna estructura de dependencia tendría que hacerse un analisis de dependencia con cópulas y simulación pero carecí de tiempo para realizarlo. No obstante, con el análisis exploratorio que realicé no encontré indicios de anomalías en los datos. El muestreo con el que se obtuvo la base parece haber estado bien aleatorizado y tal vez la muestra sea representativa de la población. 

Aun así, los clusters fueron claros y a pesar de que no pude anexar al documento la visualización de ellos (la anexo en el repositorio), la gráfica los muestra bien separados con un ligero overlap de observaciones. 



